{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frVG0dlJYj_o"
      },
      "outputs": [],
      "source": [
        "# Import libraries here\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import pytz\n",
        "from IPython.display import VimeoVideo\n",
        "from pymongo import MongoClient\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import wqet_grader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = MongoClient(host=\"localhost\", port=27017)\n",
        "# Connect to the \"air-quality\" database\n",
        "db = client[\"air-quality\"]\n",
        "print(db.list_collection_names())\n",
        "\n",
        "# Access the collection for Dar es Salaam\n",
        "dar = db[\"dar-es-salaam\"]"
      ],
      "metadata": {
        "id": "EmbKWezUZY9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sites = dar.distinct(\"metadata.site\")\n",
        "sites"
      ],
      "metadata": {
        "id": "YPzttOHKZbc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = dar.aggregate(\n",
        "    [\n",
        "        {\"$group\": {\"_id\": \"$metadata.site\", \"count\": {\"$count\": {}}}}\n",
        "    ]\n",
        ")\n",
        "readings_per_site = list(result)\n",
        "readings_per_site\n"
      ],
      "metadata": {
        "id": "gi_QyQJGZeON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrangle(collection):\n",
        "    results = collection.find(\n",
        "        {\"metadata.site\": 11, \"metadata.measurement\": \"P2\"},\n",
        "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},   # ---> focus/ limit to only \"P2\" and timestamp\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame(results).set_index(\"timestamp\")\n",
        "\n",
        "    # Localize time\n",
        "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Dar_es_Salaam\")\n",
        "\n",
        "    # Remove outliers\n",
        "    df = df[df[\"P2\"] < 100]\n",
        "\n",
        "    # Resample to 1hour period, fill in missing values\n",
        "    y = df[\"P2\"].resample(\"1H\").mean().fillna(method='ffill')\n",
        "\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "OwUilN6mZgfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"PM2.5 Level\")\n",
        "plt.title(\"Dar es Salaam PM2.5 Levels\");\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/3-5-5.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "E-5EVfqBZjAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/3-5-6.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "7yy58q1_ZncZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/3-5-7.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "pkpA0qiHZqM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/3-5-8.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "J6jgQ9_ZZssc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_test = int(len(y) * 0.90)\n",
        "y_train = y.iloc[:cutoff_test]\n",
        "y_test = y.iloc[cutoff_test:]\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "Jwmw9GTOZvQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_mean = y_train.mean()\n",
        "y_pred_baseline = [y_train_mean] * len(y_train)\n",
        "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
        "\n",
        "print(\"Mean P2 Reading:\", y_train_mean)\n",
        "print(\"Baseline MAE:\", mae_baseline)"
      ],
      "metadata": {
        "id": "dTAoXtkHZx-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "\n",
        "# Use AR model to predict PM2.5 readings\n",
        "# Define hyperparameter range\n",
        "p_params = range(1, 31)  # lag values from 1 to 30\n",
        "maes = []\n",
        "\n",
        "# Loop through each hyperparameter\n",
        "for p in p_params:\n",
        "    # Train the AR model\n",
        "    model = AutoReg(y_train, lags=p).fit()\n",
        "\n",
        "    # Generate predictions\n",
        "    y_pred = model.predict().dropna()\n",
        "\n",
        "    # Calculate mean absolute error\n",
        "    mae = mean_absolute_error(y_train.iloc[p:], y_pred)\n",
        "    maes.append(mae)\n",
        "\n",
        "# Store results in a pandas Series\n",
        "mae_series = pd.Series(maes, name=\"mae\", index=p_params)\n",
        "print(mae_series.head())\n"
      ],
      "metadata": {
        "id": "VpwlNUCmZ0OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Locate the best hyperparameter value of p\n",
        "best_p = 28  # Replace with the value that minimizes the MAE from Task 3.5.11\n",
        "\n",
        "# Build and train the model using the best p\n",
        "best_model = AutoReg(y_train, lags=best_p).fit()\n",
        "\n",
        "# Calculate residuals for the best model\n",
        "y_train_resid = best_model.resid\n",
        "y_train_resid.name = \"residuals\"\n",
        "\n",
        "# Display residuals\n",
        "print(y_train_resid.head())\n"
      ],
      "metadata": {
        "id": "OBuSYqNBZ2BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the training residuals for the best model\n",
        "y_train_resid = best_model.resid\n",
        "y_train_resid.name = \"residuals\"\n",
        "\n",
        "# Display the last 1500 residuals\n",
        "print(y_train_resid.tail(1500))\n"
      ],
      "metadata": {
        "id": "hIgVaQm5aZ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/3-5-15.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "mNrjQbZ5aiw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# walk-forward validation for model for test data --> y_test\n",
        "# predictions stored in series: y_pred_wfv\n",
        "y_pred_wfv = pd.Series()\n",
        "history = y_train.copy()\n",
        "for i in range(len(y_test)):\n",
        "    model = AutoReg(history, lags=best_p).fit()\n",
        "    next_pred = model.forecast()      # next value after end of history\n",
        "    y_pred_wfv = y_pred_wfv.append(next_pred)\n",
        "    history = history.append(y_test[next_pred.index])\n",
        "\n",
        "y_pred_wfv.name = \"prediction\"\n",
        "y_pred_wfv.index.name = \"timestamp\"\n",
        "y_pred_wfv.head()"
      ],
      "metadata": {
        "id": "xELia7DVajkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Put test and walk-forward validation values\n",
        "# in a dataframe and plot df\n",
        "df_pred_test = pd.DataFrame(\n",
        "    {\"y_test\": y_test, \"y_pred_wfv\": y_pred_wfv}\n",
        ")\n",
        "fig = px.line(df_pred_test, labels={\"value\": \"PM2.5\"})\n",
        "fig.update_layout(\n",
        "    title=\"Dar es Salaam, WFV Predictions\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"PM2.5 Level\",\n",
        ")\n",
        "\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "fig.write_image(\"images/3-5-18.png\", scale=1, height=500, width=700)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GXwyY35AalZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}